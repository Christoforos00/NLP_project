{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nlp_hw3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Christoforos00/NLP_project/blob/main/nlp_hw3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD4Xay0Hm9F8"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRj3YEpGrVSo",
        "outputId": "74bd5019-2368-4b17-8203-e49728bed805"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96CNevkqyjLm"
      },
      "source": [
        "df = pd.read_json('/content/drive/My Drive/News_Category_Dataset_v2.json', lines=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nYVaQIFSzCVr",
        "outputId": "ceda719a-1f73-48d8-efeb-000e2e8697c3"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>headline</th>\n",
              "      <th>authors</th>\n",
              "      <th>link</th>\n",
              "      <th>short_description</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CRIME</td>\n",
              "      <td>There Were 2 Mass Shootings In Texas Last Week...</td>\n",
              "      <td>Melissa Jeltsen</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/texas-ama...</td>\n",
              "      <td>She left her husband. He killed their children...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Will Smith Joins Diplo And Nicky Jam For The 2...</td>\n",
              "      <td>Andy McDonald</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/will-smit...</td>\n",
              "      <td>Of course it has a song.</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Hugh Grant Marries For The First Time At Age 57</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/hugh-gran...</td>\n",
              "      <td>The actor and his longtime girlfriend Anna Ebe...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Jim Carrey Blasts 'Castrato' Adam Schiff And D...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/jim-carre...</td>\n",
              "      <td>The actor gives Dems an ass-kicking for not fi...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTERTAINMENT</td>\n",
              "      <td>Julianna Margulies Uses Donald Trump Poop Bags...</td>\n",
              "      <td>Ron Dicker</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/julianna-...</td>\n",
              "      <td>The \"Dietland\" actress said using the bags is ...</td>\n",
              "      <td>2018-05-26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200848</th>\n",
              "      <td>TECH</td>\n",
              "      <td>RIM CEO Thorsten Heins' 'Significant' Plans Fo...</td>\n",
              "      <td>Reuters, Reuters</td>\n",
              "      <td>https://www.huffingtonpost.com/entry/rim-ceo-t...</td>\n",
              "      <td>Verizon Wireless and AT&amp;T are already promotin...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200849</th>\n",
              "      <td>SPORTS</td>\n",
              "      <td>Maria Sharapova Stunned By Victoria Azarenka I...</td>\n",
              "      <td></td>\n",
              "      <td>https://www.huffingtonpost.com/entry/maria-sha...</td>\n",
              "      <td>Afterward, Azarenka, more effusive with the pr...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200850</th>\n",
              "      <td>SPORTS</td>\n",
              "      <td>Giants Over Patriots, Jets Over Colts Among  M...</td>\n",
              "      <td></td>\n",
              "      <td>https://www.huffingtonpost.com/entry/super-bow...</td>\n",
              "      <td>Leading up to Super Bowl XLVI, the most talked...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200851</th>\n",
              "      <td>SPORTS</td>\n",
              "      <td>Aldon Smith Arrested: 49ers Linebacker Busted ...</td>\n",
              "      <td></td>\n",
              "      <td>https://www.huffingtonpost.com/entry/aldon-smi...</td>\n",
              "      <td>CORRECTION: An earlier version of this story i...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200852</th>\n",
              "      <td>SPORTS</td>\n",
              "      <td>Dwight Howard Rips Teammates After Magic Loss ...</td>\n",
              "      <td></td>\n",
              "      <td>https://www.huffingtonpost.com/entry/dwight-ho...</td>\n",
              "      <td>The five-time all-star center tore into his te...</td>\n",
              "      <td>2012-01-28</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200853 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             category  ...       date\n",
              "0               CRIME  ... 2018-05-26\n",
              "1       ENTERTAINMENT  ... 2018-05-26\n",
              "2       ENTERTAINMENT  ... 2018-05-26\n",
              "3       ENTERTAINMENT  ... 2018-05-26\n",
              "4       ENTERTAINMENT  ... 2018-05-26\n",
              "...               ...  ...        ...\n",
              "200848           TECH  ... 2012-01-28\n",
              "200849         SPORTS  ... 2012-01-28\n",
              "200850         SPORTS  ... 2012-01-28\n",
              "200851         SPORTS  ... 2012-01-28\n",
              "200852         SPORTS  ... 2012-01-28\n",
              "\n",
              "[200853 rows x 6 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "heZEqGvB6_48"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True)\n",
        "df = df[:100000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3i_QoR8zeNg"
      },
      "source": [
        "df['text'] = df['headline'] + \" \" + df['short_description']\n",
        "texts = df['text'].tolist() \n",
        "labels = df['category'].tolist()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDvcLmdE5jib"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cT1_omKCnMJN"
      },
      "source": [
        "# Νέα ενότητα"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLXCtRcmoNz7"
      },
      "source": [
        "del df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtqwJML3B3D-"
      },
      "source": [
        "import spacy\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm',disable=[\"tagger\", \"parser\",\"ner\"])\n",
        "nlp.add_pipe(nlp.create_pipe('sentencizer')) \n",
        "\n",
        "def tokenize_samples(samples):\n",
        "  \n",
        "    tokenized_samples = []\n",
        "    for i in range(len(samples)):  # For each sample\n",
        "        doc = nlp(samples[i])  # Tokenize the sample into sentences\n",
        "        tokens = []\n",
        "        for sent in doc.sents:  # For each sentence\n",
        "            for tok in sent:  # Iterate through each token \n",
        "                # Preprocessing: Filter stopwords\n",
        "                if '\\n' in tok.text or \"\\t\" in tok.text or \"--\" in tok.text or \"*\" in tok.text or tok.text.lower() in STOP_WORDS:\n",
        "                    continue\n",
        "                if tok.text.strip():  \n",
        "                    tokens.append(tok.text.replace('\"',\"'\").strip())\n",
        "        tokenized_samples.append(tokens)\n",
        "\n",
        "    return tokenized_samples\n",
        "\n",
        "texts_tokenized = tokenize_samples(texts)\n",
        "text_edited = texts_tokenized\n",
        "texts_tokenized = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oT8zMWjPm9GB",
        "outputId": "e77232f5-950a-4bb9-bf9f-2fea0f01786a"
      },
      "source": [
        "\n",
        "nltk.download('wordnet')\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "stemmer = WordNetLemmatizer()\n",
        "text_edited = []\n",
        "\n",
        "for text in texts: \n",
        "\n",
        "    # Remove all the special characters\n",
        "    text = re.sub('\\W', ' ', str(text))\n",
        "    \n",
        "    # Remove \\n\n",
        "    text = re.sub('\\s+[\\\\n\\\\r]+', '', text)\n",
        "   \n",
        "    # Remove all single characters\n",
        "    text = re.sub('\\s+[a-zA-Z]\\s+', ' ', text)\n",
        "\n",
        "    # Substitute multiple spaces with single space\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "\n",
        "    # Convert to lowercase\n",
        "    text = text.lower()\n",
        "\n",
        "    # Split the documents based on whitespace \n",
        "    text = text.split()\n",
        "\n",
        "    # Lemmatization\n",
        "    text = [stemmer.lemmatize(word) for word in text]\n",
        "\n",
        "    # Reconstruct the document by joining the words on each whitespace\n",
        "    text = ' '.join(text)\n",
        "\n",
        "    text_edited.append(text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbnZEtQym9GC"
      },
      "source": [
        "from sklearn.model_selection import train_test_split  \n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(text_edited, labels, test_size=0.2, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIDaGWHsCPDK"
      },
      "source": [
        "# Load/deserialize\n",
        "fasttext_embed = np.load(\"/content/drive/My Drive/fasttext.npy\")\n",
        "fasttext_word_to_index = pickle.load(open(\"/content/drive/My Drive/fasttext_voc.pkl\", 'rb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFfjR35ICGXV"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "MAX_WORDS = 100000\n",
        "MAX_SEQUENCE_LENGTH = 250 \n",
        "EMBEDDING_DIM = fasttext_embed.shape[1]\n",
        "\n",
        "# Init tokenizer\n",
        "tokenizer = Tokenizer(num_words=MAX_WORDS, oov_token='__UNK__')\n",
        "# num_words: the maximum number of words to keep, based on word frequency.\n",
        "# oov_token: will be used to replace OOV WORDS\n",
        "\n",
        "# Fit tokenizer\n",
        "tokenizer.fit_on_texts([\" \".join(x) for x in X_train])\n",
        "\n",
        "# Converts text to sequences of IDs\n",
        "train_seqs = tokenizer.texts_to_sequences([\" \".join(x) for x in X_train])\n",
        "test_seqs = tokenizer.texts_to_sequences([\" \".join(x) for x in X_test])\n",
        "\n",
        "# Pads sequences to a fixed value\n",
        "X_train = pad_sequences(sequences=train_seqs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')\n",
        "X_test = pad_sequences(sequences=test_seqs, maxlen=MAX_SEQUENCE_LENGTH, padding='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGWOW0TJ2kOB"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# Exclude stopwords\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Vectorize the text\n",
        "vectorizer = TfidfVectorizer(\n",
        "    ngram_range=(1, 2),  # Use unigram & bi-gram tf*idf features\n",
        "    max_features = 5000,  # Keep top 5000 features \n",
        "    sublinear_tf=True,  # Replace tf with 1 + log(tf)\n",
        "    stop_words=stopwords.words('english'))  # Remove stopwords\n",
        "\n",
        "# Fit Vectorizer on train data\n",
        "# Transform on all data\n",
        "X_train = vectorizer.fit_transform(X_train) \n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "print(vectorizer.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0D76y1t2kxI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxW6PFUh3ZPL"
      },
      "source": [
        "del text_edited\n",
        "del labels\n",
        "\n",
        "\n",
        "y_train = np.array(y_train)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgVenaTk4Bfl"
      },
      "source": [
        "# Reduce dimensionality using svd 5000 --> 500\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "\n",
        "svd = TruncatedSVD(n_components=500, random_state=4321)\n",
        "X_train = svd.fit_transform(X_train)\n",
        "X_test = svd.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Av4SQAO9CAwu"
      },
      "source": [
        "from sklearn.preprocessing import LabelBinarizer\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "y_train = lb.fit_transform(y_train)\n",
        "# y_dev = lb.transform(y_dev)\n",
        "y_test = lb.transform(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHfMy9UW3gsM"
      },
      "source": [
        "X_train, X_dev, y_train, y_dev = train_test_split(X_train, y_train, test_size=0.25, random_state=101)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG-cust7BPnQ"
      },
      "source": [
        "y_train_nonbinary = lb.inverse_transform(y_train)\n",
        "y_dev_nonbinary = lb.inverse_transform(y_dev)\n",
        "y_test_nonbinary = lb.inverse_transform(y_test )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLIcOri4-m51"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rGp_EO7Am9GF",
        "outputId": "7f345234-fa08-44fa-a60a-ee654d81d5a6"
      },
      "source": [
        "print(\"Results of the majority classifier\")\n",
        "\n",
        "baseline = DummyClassifier(strategy='most_frequent')\n",
        "baseline.fit(X_train, y_train_nonbinary)\n",
        "\n",
        "print(\"Classification report on the training data:\")\n",
        "predictions_train = baseline.predict(X_train)\n",
        "print(classification_report(y_train_nonbinary, predictions_train))\n",
        "\n",
        "print(\"Classification report on the development data:\")\n",
        "predictions_dev = baseline.predict(X_dev)\n",
        "print(classification_report(y_dev_nonbinary, predictions_dev))\n",
        "\n",
        "print(\"Classification report on the test data:\")\n",
        "predictions_test = baseline.predict(X_test)\n",
        "print(classification_report(y_test_nonbinary, predictions_test))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results of the majority classifier\n",
            "Classification report on the training data:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.00      0.00      0.00       479\n",
            "ARTS & CULTURE       0.00      0.00      0.00       387\n",
            "  BLACK VOICES       0.00      0.00      0.00      1419\n",
            "      BUSINESS       0.00      0.00      0.00      1791\n",
            "       COLLEGE       0.00      0.00      0.00       344\n",
            "        COMEDY       0.00      0.00      0.00      1488\n",
            "         CRIME       0.00      0.00      0.00      1054\n",
            "CULTURE & ARTS       0.00      0.00      0.00       297\n",
            "       DIVORCE       0.00      0.00      0.00      1025\n",
            "     EDUCATION       0.00      0.00      0.00       285\n",
            " ENTERTAINMENT       0.00      0.00      0.00      4864\n",
            "   ENVIRONMENT       0.00      0.00      0.00       408\n",
            "         FIFTY       0.00      0.00      0.00       420\n",
            "  FOOD & DRINK       0.00      0.00      0.00      1827\n",
            "     GOOD NEWS       0.00      0.00      0.00       381\n",
            "         GREEN       0.00      0.00      0.00       767\n",
            "HEALTHY LIVING       0.00      0.00      0.00      1972\n",
            " HOME & LIVING       0.00      0.00      0.00      1253\n",
            "        IMPACT       0.00      0.00      0.00      1010\n",
            " LATINO VOICES       0.00      0.00      0.00       336\n",
            "         MEDIA       0.00      0.00      0.00       845\n",
            "         MONEY       0.00      0.00      0.00       492\n",
            "     PARENTING       0.00      0.00      0.00      2605\n",
            "       PARENTS       0.00      0.00      0.00      1186\n",
            "      POLITICS       0.16      1.00      0.28      9743\n",
            "  QUEER VOICES       0.00      0.00      0.00      1899\n",
            "      RELIGION       0.00      0.00      0.00       792\n",
            "       SCIENCE       0.00      0.00      0.00       649\n",
            "        SPORTS       0.00      0.00      0.00      1457\n",
            "         STYLE       0.00      0.00      0.00       680\n",
            "STYLE & BEAUTY       0.00      0.00      0.00      2887\n",
            "         TASTE       0.00      0.00      0.00       622\n",
            "          TECH       0.00      0.00      0.00       642\n",
            " THE WORLDPOST       0.00      0.00      0.00      1095\n",
            "        TRAVEL       0.00      0.00      0.00      2932\n",
            "      WEDDINGS       0.00      0.00      0.00      1070\n",
            "    WEIRD NEWS       0.00      0.00      0.00       830\n",
            "      WELLNESS       0.00      0.00      0.00      5342\n",
            "         WOMEN       0.00      0.00      0.00      1006\n",
            "    WORLD NEWS       0.00      0.00      0.00       661\n",
            "     WORLDPOST       0.00      0.00      0.00       758\n",
            "\n",
            "      accuracy                           0.16     60000\n",
            "     macro avg       0.00      0.02      0.01     60000\n",
            "  weighted avg       0.03      0.16      0.05     60000\n",
            "\n",
            "Classification report on the development data:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.00      0.00      0.00       167\n",
            "ARTS & CULTURE       0.00      0.00      0.00       133\n",
            "  BLACK VOICES       0.00      0.00      0.00       445\n",
            "      BUSINESS       0.00      0.00      0.00       542\n",
            "       COLLEGE       0.00      0.00      0.00       102\n",
            "        COMEDY       0.00      0.00      0.00       565\n",
            "         CRIME       0.00      0.00      0.00       319\n",
            "CULTURE & ARTS       0.00      0.00      0.00       112\n",
            "       DIVORCE       0.00      0.00      0.00       318\n",
            "     EDUCATION       0.00      0.00      0.00       102\n",
            " ENTERTAINMENT       0.00      0.00      0.00      1606\n",
            "   ENVIRONMENT       0.00      0.00      0.00       107\n",
            "         FIFTY       0.00      0.00      0.00       119\n",
            "  FOOD & DRINK       0.00      0.00      0.00       641\n",
            "     GOOD NEWS       0.00      0.00      0.00       136\n",
            "         GREEN       0.00      0.00      0.00       235\n",
            "HEALTHY LIVING       0.00      0.00      0.00       691\n",
            " HOME & LIVING       0.00      0.00      0.00       441\n",
            "        IMPACT       0.00      0.00      0.00       337\n",
            " LATINO VOICES       0.00      0.00      0.00       105\n",
            "         MEDIA       0.00      0.00      0.00       304\n",
            "         MONEY       0.00      0.00      0.00       152\n",
            "     PARENTING       0.00      0.00      0.00       843\n",
            "       PARENTS       0.00      0.00      0.00       406\n",
            "      POLITICS       0.16      1.00      0.28      3288\n",
            "  QUEER VOICES       0.00      0.00      0.00       605\n",
            "      RELIGION       0.00      0.00      0.00       254\n",
            "       SCIENCE       0.00      0.00      0.00       229\n",
            "        SPORTS       0.00      0.00      0.00       503\n",
            "         STYLE       0.00      0.00      0.00       209\n",
            "STYLE & BEAUTY       0.00      0.00      0.00       933\n",
            "         TASTE       0.00      0.00      0.00       247\n",
            "          TECH       0.00      0.00      0.00       237\n",
            " THE WORLDPOST       0.00      0.00      0.00       394\n",
            "        TRAVEL       0.00      0.00      0.00       998\n",
            "      WEDDINGS       0.00      0.00      0.00       340\n",
            "    WEIRD NEWS       0.00      0.00      0.00       247\n",
            "      WELLNESS       0.00      0.00      0.00      1758\n",
            "         WOMEN       0.00      0.00      0.00       337\n",
            "    WORLD NEWS       0.00      0.00      0.00       216\n",
            "     WORLDPOST       0.00      0.00      0.00       277\n",
            "\n",
            "      accuracy                           0.16     20000\n",
            "     macro avg       0.00      0.02      0.01     20000\n",
            "  weighted avg       0.03      0.16      0.05     20000\n",
            "\n",
            "Classification report on the test data:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.00      0.00      0.00       145\n",
            "ARTS & CULTURE       0.00      0.00      0.00       145\n",
            "  BLACK VOICES       0.00      0.00      0.00       448\n",
            "      BUSINESS       0.00      0.00      0.00       625\n",
            "       COLLEGE       0.00      0.00      0.00       112\n",
            "        COMEDY       0.00      0.00      0.00       508\n",
            "         CRIME       0.00      0.00      0.00       306\n",
            "CULTURE & ARTS       0.00      0.00      0.00        99\n",
            "       DIVORCE       0.00      0.00      0.00       347\n",
            "     EDUCATION       0.00      0.00      0.00       111\n",
            " ENTERTAINMENT       0.00      0.00      0.00      1647\n",
            "   ENVIRONMENT       0.00      0.00      0.00       139\n",
            "         FIFTY       0.00      0.00      0.00       155\n",
            "  FOOD & DRINK       0.00      0.00      0.00       592\n",
            "     GOOD NEWS       0.00      0.00      0.00       136\n",
            "         GREEN       0.00      0.00      0.00       266\n",
            "HEALTHY LIVING       0.00      0.00      0.00       665\n",
            " HOME & LIVING       0.00      0.00      0.00       411\n",
            "        IMPACT       0.00      0.00      0.00       369\n",
            " LATINO VOICES       0.00      0.00      0.00       105\n",
            "         MEDIA       0.00      0.00      0.00       254\n",
            "         MONEY       0.00      0.00      0.00       161\n",
            "     PARENTING       0.00      0.00      0.00       911\n",
            "       PARENTS       0.00      0.00      0.00       448\n",
            "      POLITICS       0.16      1.00      0.28      3258\n",
            "  QUEER VOICES       0.00      0.00      0.00       610\n",
            "      RELIGION       0.00      0.00      0.00       258\n",
            "       SCIENCE       0.00      0.00      0.00       210\n",
            "        SPORTS       0.00      0.00      0.00       482\n",
            "         STYLE       0.00      0.00      0.00       208\n",
            "STYLE & BEAUTY       0.00      0.00      0.00       914\n",
            "         TASTE       0.00      0.00      0.00       205\n",
            "          TECH       0.00      0.00      0.00       200\n",
            " THE WORLDPOST       0.00      0.00      0.00       338\n",
            "        TRAVEL       0.00      0.00      0.00      1004\n",
            "      WEDDINGS       0.00      0.00      0.00       369\n",
            "    WEIRD NEWS       0.00      0.00      0.00       242\n",
            "      WELLNESS       0.00      0.00      0.00      1741\n",
            "         WOMEN       0.00      0.00      0.00       393\n",
            "    WORLD NEWS       0.00      0.00      0.00       213\n",
            "     WORLDPOST       0.00      0.00      0.00       250\n",
            "\n",
            "      accuracy                           0.16     20000\n",
            "     macro avg       0.00      0.02      0.01     20000\n",
            "  weighted avg       0.03      0.16      0.05     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmkcV16zm9GF",
        "outputId": "5bae1415-54c7-456a-e77d-c2786815459c"
      },
      "source": [
        "print(\"Results of logistic regression\")\n",
        "\n",
        "logReg = LogisticRegression(solver=\"liblinear\", C = 10)\n",
        "logReg.fit(X_train, y_train_nonbinary)\n",
        "\n",
        "print(\"Classification report on the training data:\")\n",
        "predictions_train = logReg.predict(X_train)\n",
        "print(classification_report(y_train_nonbinary, predictions_train))\n",
        "\n",
        "print(\"Classification report on the development data:\")\n",
        "predictions_dev = logReg.predict(X_dev)\n",
        "print(classification_report(y_dev_nonbinary, predictions_dev))\n",
        "\n",
        "print(\"Classification report on the test data:\")\n",
        "predictions_test = logReg.predict(X_test)\n",
        "print(classification_report(y_test_nonbinary, predictions_test))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Results of logistic regression\n",
            "Classification report on the training data:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.47      0.18      0.26       457\n",
            "ARTS & CULTURE       0.46      0.16      0.23       411\n",
            "  BLACK VOICES       0.49      0.27      0.35      1375\n",
            "      BUSINESS       0.47      0.42      0.45      1756\n",
            "       COLLEGE       0.49      0.33      0.39       368\n",
            "        COMEDY       0.53      0.30      0.38      1576\n",
            "         CRIME       0.56      0.55      0.55      1010\n",
            "CULTURE & ARTS       0.63      0.24      0.35       331\n",
            "       DIVORCE       0.78      0.64      0.70      1003\n",
            "     EDUCATION       0.53      0.33      0.41       302\n",
            " ENTERTAINMENT       0.46      0.70      0.55      4868\n",
            "   ENVIRONMENT       0.72      0.18      0.28       410\n",
            "         FIFTY       0.39      0.07      0.11       399\n",
            "  FOOD & DRINK       0.59      0.71      0.64      1916\n",
            "     GOOD NEWS       0.49      0.18      0.26       439\n",
            "         GREEN       0.45      0.31      0.37       796\n",
            "HEALTHY LIVING       0.36      0.14      0.20      1969\n",
            " HOME & LIVING       0.67      0.65      0.66      1277\n",
            "        IMPACT       0.41      0.20      0.27      1001\n",
            " LATINO VOICES       0.62      0.05      0.10       346\n",
            "         MEDIA       0.51      0.27      0.35       829\n",
            "         MONEY       0.54      0.29      0.38       502\n",
            "     PARENTING       0.50      0.62      0.55      2547\n",
            "       PARENTS       0.50      0.21      0.30      1155\n",
            "      POLITICS       0.62      0.85      0.71      9772\n",
            "  QUEER VOICES       0.71      0.61      0.66      1903\n",
            "      RELIGION       0.61      0.35      0.44       775\n",
            "       SCIENCE       0.58      0.36      0.45       650\n",
            "        SPORTS       0.58      0.52      0.55      1466\n",
            "         STYLE       0.59      0.19      0.29       675\n",
            "STYLE & BEAUTY       0.68      0.77      0.72      2821\n",
            "         TASTE       0.58      0.10      0.17       609\n",
            "          TECH       0.56      0.39      0.46       624\n",
            " THE WORLDPOST       0.50      0.41      0.45      1081\n",
            "        TRAVEL       0.60      0.74      0.66      2942\n",
            "      WEDDINGS       0.79      0.75      0.77      1059\n",
            "    WEIRD NEWS       0.42      0.18      0.26       789\n",
            "      WELLNESS       0.50      0.79      0.61      5377\n",
            "         WOMEN       0.41      0.28      0.33      1008\n",
            "    WORLD NEWS       0.42      0.07      0.12       615\n",
            "     WORLDPOST       0.46      0.19      0.27       791\n",
            "\n",
            "      accuracy                           0.56     60000\n",
            "     macro avg       0.54      0.38      0.42     60000\n",
            "  weighted avg       0.55      0.56      0.53     60000\n",
            "\n",
            "Classification report on the development data:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.29      0.09      0.14       147\n",
            "ARTS & CULTURE       0.31      0.11      0.16       132\n",
            "  BLACK VOICES       0.53      0.26      0.34       477\n",
            "      BUSINESS       0.44      0.41      0.42       566\n",
            "       COLLEGE       0.33      0.25      0.29       108\n",
            "        COMEDY       0.45      0.24      0.31       502\n",
            "         CRIME       0.53      0.48      0.50       369\n",
            "CULTURE & ARTS       0.35      0.15      0.21       100\n",
            "       DIVORCE       0.76      0.61      0.67       340\n",
            "     EDUCATION       0.30      0.21      0.24        87\n",
            " ENTERTAINMENT       0.46      0.70      0.56      1620\n",
            "   ENVIRONMENT       0.65      0.19      0.29       139\n",
            "         FIFTY       0.14      0.02      0.03       116\n",
            "  FOOD & DRINK       0.55      0.67      0.61       597\n",
            "     GOOD NEWS       0.26      0.09      0.13       152\n",
            "         GREEN       0.39      0.25      0.31       271\n",
            "HEALTHY LIVING       0.29      0.11      0.16       693\n",
            " HOME & LIVING       0.61      0.59      0.60       406\n",
            "        IMPACT       0.35      0.14      0.20       340\n",
            " LATINO VOICES       0.50      0.03      0.06       101\n",
            "         MEDIA       0.46      0.27      0.34       263\n",
            "         MONEY       0.49      0.23      0.32       162\n",
            "     PARENTING       0.48      0.55      0.51       901\n",
            "       PARENTS       0.34      0.16      0.22       380\n",
            "      POLITICS       0.60      0.84      0.70      3264\n",
            "  QUEER VOICES       0.66      0.59      0.62       629\n",
            "      RELIGION       0.53      0.32      0.40       247\n",
            "       SCIENCE       0.48      0.26      0.34       213\n",
            "        SPORTS       0.58      0.51      0.54       490\n",
            "         STYLE       0.48      0.13      0.20       238\n",
            "STYLE & BEAUTY       0.67      0.76      0.71       943\n",
            "         TASTE       0.28      0.04      0.07       210\n",
            "          TECH       0.51      0.29      0.37       224\n",
            " THE WORLDPOST       0.44      0.35      0.39       387\n",
            "        TRAVEL       0.59      0.72      0.65       985\n",
            "      WEDDINGS       0.73      0.71      0.72       350\n",
            "    WEIRD NEWS       0.33      0.13      0.19       262\n",
            "      WELLNESS       0.47      0.77      0.58      1778\n",
            "         WOMEN       0.35      0.24      0.29       341\n",
            "    WORLD NEWS       0.49      0.08      0.13       236\n",
            "     WORLDPOST       0.30      0.14      0.19       234\n",
            "\n",
            "      accuracy                           0.53     20000\n",
            "     macro avg       0.46      0.33      0.36     20000\n",
            "  weighted avg       0.51      0.53      0.49     20000\n",
            "\n",
            "Classification report on the test data:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.30      0.09      0.14       169\n",
            "ARTS & CULTURE       0.35      0.10      0.16       138\n",
            "  BLACK VOICES       0.43      0.24      0.30       431\n",
            "      BUSINESS       0.43      0.35      0.39       610\n",
            "       COLLEGE       0.46      0.33      0.38       103\n",
            "        COMEDY       0.44      0.26      0.33       476\n",
            "         CRIME       0.49      0.46      0.47       312\n",
            "CULTURE & ARTS       0.50      0.14      0.22       107\n",
            "       DIVORCE       0.78      0.63      0.70       360\n",
            "     EDUCATION       0.45      0.31      0.37        96\n",
            " ENTERTAINMENT       0.41      0.67      0.51      1601\n",
            "   ENVIRONMENT       0.58      0.14      0.23       152\n",
            "         FIFTY       0.30      0.04      0.08       137\n",
            "  FOOD & DRINK       0.52      0.69      0.59       576\n",
            "     GOOD NEWS       0.24      0.06      0.10       127\n",
            "         GREEN       0.37      0.22      0.27       291\n",
            "HEALTHY LIVING       0.26      0.09      0.13       639\n",
            " HOME & LIVING       0.63      0.60      0.61       424\n",
            "        IMPACT       0.41      0.18      0.25       354\n",
            " LATINO VOICES       0.50      0.03      0.06       100\n",
            "         MEDIA       0.52      0.28      0.36       278\n",
            "         MONEY       0.51      0.24      0.32       159\n",
            "     PARENTING       0.46      0.56      0.50       837\n",
            "       PARENTS       0.35      0.17      0.23       376\n",
            "      POLITICS       0.59      0.84      0.69      3168\n",
            "  QUEER VOICES       0.66      0.57      0.61       620\n",
            "      RELIGION       0.56      0.31      0.40       261\n",
            "       SCIENCE       0.51      0.27      0.36       217\n",
            "        SPORTS       0.55      0.48      0.51       505\n",
            "         STYLE       0.51      0.14      0.22       251\n",
            "STYLE & BEAUTY       0.67      0.74      0.70       972\n",
            "         TASTE       0.25      0.02      0.04       250\n",
            "          TECH       0.46      0.29      0.35       203\n",
            " THE WORLDPOST       0.43      0.31      0.36       391\n",
            "        TRAVEL       0.57      0.71      0.64      1030\n",
            "      WEDDINGS       0.75      0.66      0.70       361\n",
            "    WEIRD NEWS       0.32      0.13      0.18       286\n",
            "      WELLNESS       0.48      0.78      0.59      1752\n",
            "         WOMEN       0.39      0.28      0.33       361\n",
            "    WORLD NEWS       0.35      0.05      0.09       240\n",
            "     WORLDPOST       0.40      0.15      0.22       279\n",
            "\n",
            "      accuracy                           0.52     20000\n",
            "     macro avg       0.47      0.33      0.36     20000\n",
            "  weighted avg       0.50      0.52      0.48     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kCeTJBECHBhA"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding,Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjgFZtPdwnwa",
        "outputId": "9a095ce4-e0b7-4ffa-b41c-6c31ee773106"
      },
      "source": [
        "pip install keras-tuner --upgrade"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.0.4-py3-none-any.whl (97 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 21.1 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 20 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 30 kB 11.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 40 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 51 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 71 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 81 kB 4.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 92 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 97 kB 2.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.6.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.0.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.5.30)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.34.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.5)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.39.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.4.3)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.0.4 kt-legacy-1.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfVXy0uSCiEi",
        "outputId": "786aaed0-3b30-4d15-c47c-4ebefcccace1"
      },
      "source": [
        "#hyperparameter tuning\n",
        "\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(Embedding(input_dim=MAX_WORDS+2, output_dim=EMBEDDING_DIM, weights=[embedding_matrix]\n",
        "            ,input_length=MAX_SEQUENCE_LENGTH, mask_zero=True, trainable=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(layers.Dense(units=hp.Int('input_units' , min_value=64, max_value=512, step=128),input_shape= X_test[1].shape , activation='relu'))\n",
        "    \n",
        "    for i in range(hp.Int('num_layers', 1, 3)):\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i), min_value=64, max_value=512, step=128), activation='relu'))\n",
        "        model.add(Dropout(0.5))\n",
        "   \n",
        "    model.add(Dense(y_dev.shape[1],activation='softmax'))\n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=keras.optimizers.Adam(\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "        metrics=[\"accuracy\"]\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='accuracy',\n",
        "    max_trials=40,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True )\n",
        "\n",
        "tuner.search_space_summary()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "input_units (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 128, 'sampling': None}\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 64, 'max_value': 512, 'step': 128, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "X2LNa1l7Ck62",
        "outputId": "7a64b520-be98-4730-b2d1-ba36b03c49d1"
      },
      "source": [
        "with tf.device('/device:GPU:0'):  \n",
        "    tuner.search(X_train, y_train,\n",
        "                epochs=20,\n",
        "                batch_size = 256,\n",
        "                validation_data=(X_dev, y_dev))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trial 8 Complete [00h 53m 46s]\n",
            "accuracy: 0.4978000074625015\n",
            "\n",
            "Best accuracy So Far: 0.5304000079631805\n",
            "Total elapsed time: 02h 55m 11s\n",
            "\n",
            "Search: Running Trial #9\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "input_units       |192               |320               \n",
            "num_layers        |1                 |3                 \n",
            "units_0           |448               |64                \n",
            "learning_rate     |0.001             |0.001             \n",
            "units_1           |320               |64                \n",
            "units_2           |320               |64                \n",
            "\n",
            "Epoch 1/20\n",
            "235/235 [==============================] - 125s 529ms/step - loss: 2.4564 - accuracy: 0.3775 - val_loss: 1.9006 - val_accuracy: 0.4903\n",
            "Epoch 2/20\n",
            "235/235 [==============================] - 124s 527ms/step - loss: 1.8725 - accuracy: 0.4919 - val_loss: 1.7392 - val_accuracy: 0.5270\n",
            "Epoch 3/20\n",
            "235/235 [==============================] - 126s 537ms/step - loss: 1.6735 - accuracy: 0.5342 - val_loss: 1.6702 - val_accuracy: 0.5414\n",
            "Epoch 4/20\n",
            "235/235 [==============================] - ETA: 0s - loss: 1.5480 - accuracy: 0.5642"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbI3C2_HSJdZ"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxxuV20Pm9GG"
      },
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import f1_score, recall_score, precision_score\n",
        "\n",
        "class Metrics(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, valid_data):\n",
        "        super(Metrics, self).__init__()\n",
        "        self.validation_data = valid_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        logs = logs or {}\n",
        "        val_predict = np.argmax(self.model.predict(self.validation_data[0]), -1)\n",
        "        val_targ = self.validation_data[1]\n",
        "        \n",
        "        if len(val_targ.shape) == 2 and val_targ.shape[1] != 1:\n",
        "            val_targ = np.argmax(val_targ, -1)\n",
        "        val_targ = tf.cast(val_targ,dtype=tf.float32)\n",
        "        \n",
        "        _val_f1 = f1_score(val_targ, val_predict,average=\"weighted\")\n",
        "        _val_recall = recall_score(val_targ, val_predict,average=\"weighted\")\n",
        "        _val_precision = precision_score(val_targ, val_predict,average=\"weighted\")\n",
        "\n",
        "        logs['val_f1'] = _val_f1\n",
        "        logs['val_recall'] = _val_recall\n",
        "        logs['val_precision'] = _val_precision\n",
        "        print(\" — val_f1: %f — val_precision: %f — val_recall: %f\" % (_val_f1, _val_precision, _val_recall))\n",
        "        return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLdndasDBmAN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYxuNWGyBmFB",
        "outputId": "3eefcaf8-a2a7-4c1e-d48e-d50c55374f0a"
      },
      "source": [
        "word_index = tokenizer.word_index\n",
        "print('Found {} unique tokens.'.format(len(word_index)))\n",
        "\n",
        "embedding_matrix = np.zeros((MAX_WORDS+2, EMBEDDING_DIM))  # +2 (pad, unknown)\n",
        "\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_WORDS:\n",
        "            continue\n",
        "    try:\n",
        "        embedding_vector = fasttext_embed[fasttext_word_to_index[word],:]\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    except:\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 59278 unique tokens.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQjHir8Am9GG"
      },
      "source": [
        "\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "MAX_WORDS = 100000\n",
        "MAX_SEQUENCE_LENGTH = 250 \n",
        "EMBEDDING_DIM = fasttext_embed.shape[1]\n",
        "\n",
        "with tf.device('/device:GPU:0'):  \n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=MAX_WORDS+2, output_dim=EMBEDDING_DIM, weights=[embedding_matrix]\n",
        "                ,input_length=MAX_SEQUENCE_LENGTH, mask_zero=True, trainable=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(448, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(320,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(320,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(y_train.shape[1],activation='softmax'))\n",
        "\n",
        "    print(model.summary())\n",
        "    \n",
        "    \n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    if not os.path.exists('./checkpoints'):\n",
        "        os.makedirs('./checkpoints')\n",
        "        \n",
        "    checkpoint = ModelCheckpoint(\n",
        "        'checkpoints/weights.hdf5',\n",
        "        monitor='val_accuracy',\n",
        "        mode='max',\n",
        "        verbose=2,\n",
        "        save_best_only=True,\n",
        "        save_weights_only=True\n",
        "    )\n",
        "    \n",
        "    history= model.fit(\n",
        "        X_train,\n",
        "        y_train,\n",
        "        validation_data= (X_dev, y_dev),\n",
        "        batch_size=256,\n",
        "        epochs=30,\n",
        "        shuffle=True,\n",
        "        callbacks=[Metrics(valid_data=(X_dev, y_dev)), checkpoint]\n",
        "    )\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "YrLJY77fdBFi",
        "outputId": "7a8fef0b-e355-4dd7-aca8-2bbe7a5bdcd3"
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe7d8430890>]"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdzCa2RpbCt7",
        "outputId": "5dc417c4-d012-4064-b55d-db2831c636fb"
      },
      "source": [
        "import warnings\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "with tf.device('/device:GPU:0'):\n",
        "\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(input_dim=MAX_WORDS+2, output_dim=EMBEDDING_DIM, weights=[embedding_matrix]\n",
        "                ,input_length=MAX_SEQUENCE_LENGTH, mask_zero=True, trainable=False))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(448, activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(320,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(320,activation='relu'))\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(y_train.shape[1],activation='softmax'))\n",
        "\n",
        "\n",
        "    # Load weights from the pre-trained model\n",
        "    model.load_weights(\"checkpoints/weights.hdf5\")\n",
        "\n",
        "    model.compile(\n",
        "        loss='categorical_crossentropy',\n",
        "        optimizer=Adam(learning_rate=0.001),\n",
        "        metrics=[\"categorical_crossentropy\"]\n",
        "    )\n",
        "\n",
        "    print(\"Classification report on the training data:\")\n",
        "    predictions_train = model.predict(X_train)\n",
        "    predictions_train = (predictions_train > 0.5).astype(int)   \n",
        "    print(classification_report(y_train, predictions_train, target_names=lb.classes_))\n",
        "\n",
        "    print(\"Classification report on the development data:\")\n",
        "    predictions_dev = model.predict(X_dev)\n",
        "    predictions_dev = (predictions_dev > 0.5).astype(int) \n",
        "    print(classification_report(y_dev, predictions_dev, target_names=lb.classes_))\n",
        "\n",
        "    print(\"Classification report on the test data:\")\n",
        "    predictions_test = model.predict(X_test)\n",
        "    predictions_test = (predictions_test > 0.5).astype(int)    \n",
        "    print(classification_report(y_test, predictions_test, target_names=lb.classes_))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classification report on the training data:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.95      0.37      0.53       468\n",
            "ARTS & CULTURE       0.00      0.00      0.00       394\n",
            "  BLACK VOICES       1.00      0.11      0.19      1313\n",
            "      BUSINESS       0.96      0.46      0.62      1747\n",
            "       COLLEGE       0.83      0.01      0.03       348\n",
            "        COMEDY       0.88      0.38      0.53      1591\n",
            "         CRIME       0.92      0.64      0.76      1065\n",
            "CULTURE & ARTS       0.91      0.38      0.54       320\n",
            "       DIVORCE       0.92      0.79      0.85      1017\n",
            "     EDUCATION       0.96      0.07      0.14       294\n",
            " ENTERTAINMENT       0.89      0.69      0.78      4743\n",
            "   ENVIRONMENT       1.00      0.31      0.48       408\n",
            "         FIFTY       1.00      0.22      0.37       412\n",
            "  FOOD & DRINK       0.77      0.89      0.83      1873\n",
            "     GOOD NEWS       0.00      0.00      0.00       416\n",
            "         GREEN       0.87      0.39      0.54       813\n",
            "HEALTHY LIVING       0.90      0.33      0.49      1947\n",
            " HOME & LIVING       0.98      0.85      0.91      1253\n",
            "        IMPACT       0.99      0.19      0.32      1037\n",
            " LATINO VOICES       0.00      0.00      0.00       326\n",
            "         MEDIA       0.94      0.27      0.41       855\n",
            "         MONEY       0.94      0.49      0.64       516\n",
            "     PARENTING       0.86      0.66      0.74      2503\n",
            "       PARENTS       0.90      0.13      0.22      1189\n",
            "      POLITICS       0.94      0.83      0.88      9856\n",
            "  QUEER VOICES       0.93      0.62      0.75      1866\n",
            "      RELIGION       0.96      0.46      0.63       751\n",
            "       SCIENCE       0.98      0.49      0.65       668\n",
            "        SPORTS       0.95      0.81      0.87      1450\n",
            "         STYLE       0.90      0.47      0.62       680\n",
            "STYLE & BEAUTY       0.97      0.92      0.94      2825\n",
            "         TASTE       1.00      0.00      0.00       635\n",
            "          TECH       0.97      0.42      0.59       639\n",
            " THE WORLDPOST       0.68      0.58      0.63      1110\n",
            "        TRAVEL       0.99      0.86      0.92      2933\n",
            "      WEDDINGS       0.98      0.79      0.87      1122\n",
            "    WEIRD NEWS       0.82      0.09      0.16       786\n",
            "      WELLNESS       0.90      0.85      0.88      5383\n",
            "         WOMEN       0.98      0.10      0.17      1074\n",
            "    WORLD NEWS       0.00      0.00      0.00       650\n",
            "     WORLDPOST       0.96      0.61      0.75       724\n",
            "\n",
            "     micro avg       0.92      0.61      0.73     60000\n",
            "     macro avg       0.84      0.43      0.52     60000\n",
            "  weighted avg       0.90      0.61      0.69     60000\n",
            "   samples avg       0.61      0.61      0.61     60000\n",
            "\n",
            "Classification report on the development data:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.57      0.08      0.15       143\n",
            "ARTS & CULTURE       0.00      0.00      0.00       129\n",
            "  BLACK VOICES       0.67      0.01      0.03       465\n",
            "      BUSINESS       0.67      0.16      0.26       611\n",
            "       COLLEGE       0.00      0.00      0.00       134\n",
            "        COMEDY       0.76      0.19      0.30       528\n",
            "         CRIME       0.59      0.30      0.40       318\n",
            "CULTURE & ARTS       0.57      0.04      0.08        93\n",
            "       DIVORCE       0.75      0.42      0.54       356\n",
            "     EDUCATION       0.50      0.01      0.02        91\n",
            " ENTERTAINMENT       0.69      0.45      0.54      1602\n",
            "   ENVIRONMENT       0.89      0.06      0.12       127\n",
            "         FIFTY       0.40      0.02      0.03       128\n",
            "  FOOD & DRINK       0.66      0.64      0.65       585\n",
            "     GOOD NEWS       0.00      0.00      0.00       177\n",
            "         GREEN       0.47      0.12      0.19       252\n",
            "HEALTHY LIVING       0.63      0.13      0.22       674\n",
            " HOME & LIVING       0.88      0.52      0.65       431\n",
            "        IMPACT       0.36      0.01      0.03       357\n",
            " LATINO VOICES       0.00      0.00      0.00       103\n",
            "         MEDIA       0.58      0.08      0.15       262\n",
            "         MONEY       0.62      0.14      0.23       186\n",
            "     PARENTING       0.65      0.34      0.45       910\n",
            "       PARENTS       0.67      0.07      0.13       395\n",
            "      POLITICS       0.80      0.65      0.72      3183\n",
            "  QUEER VOICES       0.85      0.38      0.53       613\n",
            "      RELIGION       0.85      0.16      0.27       286\n",
            "       SCIENCE       0.80      0.17      0.28       198\n",
            "        SPORTS       0.78      0.49      0.60       507\n",
            "         STYLE       0.71      0.24      0.36       226\n",
            "STYLE & BEAUTY       0.81      0.67      0.73       952\n",
            "         TASTE       0.00      0.00      0.00       202\n",
            "          TECH       0.62      0.15      0.24       192\n",
            " THE WORLDPOST       0.61      0.36      0.45       374\n",
            "        TRAVEL       0.84      0.53      0.65      1041\n",
            "      WEDDINGS       0.86      0.52      0.65       378\n",
            "    WEIRD NEWS       0.47      0.03      0.05       277\n",
            "      WELLNESS       0.68      0.51      0.58      1718\n",
            "         WOMEN       0.79      0.03      0.06       331\n",
            "    WORLD NEWS       0.00      0.00      0.00       198\n",
            "     WORLDPOST       0.65      0.29      0.40       267\n",
            "\n",
            "     micro avg       0.74      0.38      0.50     20000\n",
            "     macro avg       0.58      0.22      0.29     20000\n",
            "  weighted avg       0.68      0.38      0.45     20000\n",
            "   samples avg       0.38      0.38      0.38     20000\n",
            "\n",
            "Classification report on the test data:\n",
            "                precision    recall  f1-score   support\n",
            "\n",
            "          ARTS       0.64      0.06      0.11       149\n",
            "ARTS & CULTURE       0.00      0.00      0.00       145\n",
            "  BLACK VOICES       0.57      0.01      0.02       442\n",
            "      BUSINESS       0.63      0.15      0.24       617\n",
            "       COLLEGE       0.00      0.00      0.00       118\n",
            "        COMEDY       0.67      0.19      0.29       510\n",
            "         CRIME       0.61      0.32      0.42       337\n",
            "CULTURE & ARTS       0.33      0.01      0.02       103\n",
            "       DIVORCE       0.78      0.49      0.60       375\n",
            "     EDUCATION       0.00      0.00      0.00       110\n",
            " ENTERTAINMENT       0.70      0.44      0.54      1573\n",
            "   ENVIRONMENT       1.00      0.06      0.12       131\n",
            "         FIFTY       0.60      0.02      0.04       140\n",
            "  FOOD & DRINK       0.65      0.63      0.64       607\n",
            "     GOOD NEWS       0.00      0.00      0.00       144\n",
            "         GREEN       0.38      0.10      0.16       256\n",
            "HEALTHY LIVING       0.51      0.11      0.18       646\n",
            " HOME & LIVING       0.82      0.46      0.59       414\n",
            "        IMPACT       0.40      0.02      0.03       350\n",
            " LATINO VOICES       0.00      0.00      0.00       121\n",
            "         MEDIA       0.52      0.05      0.09       286\n",
            "         MONEY       0.53      0.12      0.19       151\n",
            "     PARENTING       0.60      0.31      0.41       899\n",
            "       PARENTS       0.55      0.05      0.10       387\n",
            "      POLITICS       0.79      0.63      0.70      3276\n",
            "  QUEER VOICES       0.79      0.40      0.54       657\n",
            "      RELIGION       0.73      0.15      0.25       233\n",
            "       SCIENCE       0.82      0.22      0.34       213\n",
            "        SPORTS       0.77      0.45      0.57       510\n",
            "         STYLE       0.62      0.23      0.33       231\n",
            "STYLE & BEAUTY       0.79      0.65      0.71       973\n",
            "         TASTE       0.00      0.00      0.00       211\n",
            "          TECH       0.62      0.12      0.20       204\n",
            " THE WORLDPOST       0.57      0.34      0.43       355\n",
            "        TRAVEL       0.81      0.53      0.64       943\n",
            "      WEDDINGS       0.84      0.45      0.59       353\n",
            "    WEIRD NEWS       0.48      0.04      0.07       260\n",
            "      WELLNESS       0.69      0.53      0.60      1765\n",
            "         WOMEN       0.85      0.05      0.09       346\n",
            "    WORLD NEWS       0.00      0.00      0.00       204\n",
            "     WORLDPOST       0.61      0.24      0.34       255\n",
            "\n",
            "     micro avg       0.73      0.37      0.49     20000\n",
            "     macro avg       0.54      0.21      0.27     20000\n",
            "  weighted avg       0.66      0.37      0.44     20000\n",
            "   samples avg       0.37      0.37      0.37     20000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTJXB2A6xchb"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}